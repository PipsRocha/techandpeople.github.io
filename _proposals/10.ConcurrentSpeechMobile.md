---
###############
# DO NOT EDIT
layout: proposal
###############

###############
# TO EDIT
# pub title
title: "Concurrent Speech Feedback for Blind People on Touchscreens"

# publication image
image:
 name: concurrent_speech.png
 alt-text: "A headset connected to a a smartphone resting on a table." # provide a short description for the image #a11y

# short description of the publication
motivation: "Mainstream touchscreen technologies such as smartphones and tablets support non-visual access through the use of built-in screen readers (e.g., VoiceOver on iOS and Talback on Android). Screen readers enable visually impaired users to interact with the device either through gestures (e.g., swipes or taps) to navigate between elements or through an Explore by Touch approach, where users drag their finger on the screen and the UI elements are read aloud.
While these tools provide access to touchscreen devices, efficiency is limited because feedback is restricted to a sequential audio channel that contrasts with the visual information presented on screen. In this thesis, we aim to take advantage of people's ability to process simultaneous audio channels -- the Cocktail Party Effect, where one can focus the attention on a single voice, but still be able to detect interesting content in the background -- to explore solutions to convey multiple audio streams in parallel. We aim to maximize efficiency in touchscreen interaction for blind people, but without affecting their performance."

work: "In this thesis, we aim to design, develop, and evaluate auditory feedback solutions that leverage concurrent speech in the context of touchscreen interaction and exploration for visually impaired users. You will be challenged to develop system-wide services for Android devices that enable concurrent speech depending on the user context.
As an example, we expect that in some occasions notifications can be read aloud to users in parallel, without interrupting the user's current task (and feedback). 
You will conduct user studies early on to engage participants in co-design sessions ensuring user engagement and representation."

# people associated with the publication
people:
 - jpvg
 - afpr

###
---
